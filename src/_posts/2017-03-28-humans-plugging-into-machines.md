---
layout: post
title: 'Is merging our brains with computers a good idea?'
featured: "/assets/images/musk.png"
categories: future
date: 2017-03-29
type: post
comments: true
description: "Elon Musk has a new idea: connecting your brain to a computer, to enhance your life. Is it a good one? Well... maybe." 
---
The march of technology is one that seems to go on forever, and with much talk of Artificial Intelligence becoming a reality in our lifetimes it's sometimes scary to think about the implications of a future where a super-intelligent computer could help humans solve every problem we have.

We're already part-way to that incredible reality: machine learning is able to pick out the subjects of photos, down to the objects in them, along with the people photographed and where it is, without any additional context. Just a few years ago that was unthinkable.

Yesterday, Elon Musk announced he was working on something even more crazy: [a system for melding the human mind with a computer.](http://www.theverge.com/2017/3/27/15077864/elon-musk-neuralink-brain-computer-interface-ai-cyborgs) Called Neuralink, the idea is a little mirky right now, but essentially it's as simple as implanting a chip inside your brain that would help your consciousness merge with the computer.

Don't think of it as uploading your brain to a computer, but rather leveraging a computer directly to tap into more processing power. It makes sense, if you think of it: input/output devices can only ever offer us so much speed, and computers have enhanced our lives in phenomenal ways within the limitations of a simple keyboard. 

What if we could just think what we want, and the computer could help with that? Or passing thoughts could be captured by the computer and saved for later retrieval. Brilliant ideas could be passing us by every day, simply because we don't have the bandwidth to properly explore them.

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Long Neuralink piece coming out on <a href="https://twitter.com/waitbutwhy">@waitbutwhy</a> in about a week. Difficult to dedicate the time, but existential risk is too high not to.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/846580443797368832">March 28, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

That, of course could have unknown consequences: perhaps remembering everything would drive one insane. Perhaps having *too much* processing power would mean we simply burnt out faster, like a light bulb. Or, maybe it'll improve our ability to learn.

It could indeed solve a lot of problems technology faces, however. Google Glass as a contact lense could be interesting, but why even bother with shrinking the hardware like that when you could emulate it by interrupting the patterns in your neurons that provide images to your brain? The same goes for many other technologies, including typing devices, phones, cameras and more.

It's impossible to know the impact of such technology, but it does make me stop and wonder where we'll end up. The relentless march of technology is a wonder to watch, but I wonder when we'll need to step back and stop, lest we do something that we regret forever. 

What worries me, is that technology like this will eventually create a divide: those who enhance themselves with computing power inside their bodies, and those who don't. I imagine that rift will be larger than any before, simply because it becomes so deeply personal: becoming a cyborg is a huge deal.

There's also one more part: it's 2017 and we still can't make computers that don't kernel panic when you plug in a device, and phones that don't corrupt themselves out of the blue. What makes us think humanity is capable of making a chip that doesn't have a runtime error and kill someone? 

Neural lacing is something out of science fiction, and it's unlikely we'll see *any* progress in the next decade at all (at least publicly). But, in Elon Musk's own words, the reason he's doing this is because "the existential risk is too high" â€“ perhaps we can't save ourselves without it.